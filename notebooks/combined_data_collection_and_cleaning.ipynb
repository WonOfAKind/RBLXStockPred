{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-17T01:40:42.485630Z",
     "start_time": "2025-07-17T01:40:24.938663Z"
    }
   },
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pygooglenews import GoogleNews\n",
    "\n",
    "from sec_edgar_downloader import Downloader\n",
    "from pytrends.request import TrendReq\n",
    "\n",
    "# Sentiment analysis\n",
    "import finnhub\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:40:47.019358Z",
     "start_time": "2025-07-17T01:40:47.000093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Directory constants ---\n",
    "DATA_DIR = \"../data/\"\n",
    "ROMONITOR_DIR = os.path.join(DATA_DIR, \"romonitor_data\")\n",
    "SEC_DIR = os.path.join(DATA_DIR, \"sec-edgar-filings\")\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(ROMONITOR_DIR, exist_ok=True)\n",
    "os.makedirs(SEC_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Market Context Data\n",
    "def update_market_context():\n",
    "    tickers = ['^IXIC', '^VIX', '^TNX', 'XLC']\n",
    "    # Use 1 year for context\n",
    "    end = datetime.today()\n",
    "    start = \"2021-03-10\"\n",
    "    context = yf.download(tickers, start=start, end=end)['Close'].reset_index()\n",
    "    context['date'] = context['Date'].dt.strftime('%Y-%m-%d')\n",
    "    context = context.drop(columns=['Date'])\n",
    "    context.to_csv(os.path.join(DATA_DIR, 'market_context_data.csv'), index=False)\n",
    "    print(\"Updated market context data.\")\n",
    "\n",
    "# 2. Technical/Price Data\n",
    "def update_technical():\n",
    "    tickers = [\"RBLX\", \"^GSPC\", \"^IXIC\"]\n",
    "    start_date = \"2021-03-10\"\n",
    "    data = yf.download(tickers, start=start_date, group_by='ticker', auto_adjust=True)\n",
    "    rblx = data['RBLX'].copy()\n",
    "    # Add pandas_ta indicators if you want\n",
    "    rblx.to_csv(os.path.join(DATA_DIR, 'RBLX_with_technicals.csv'))\n",
    "    data['^GSPC'].to_csv(os.path.join(DATA_DIR, 'SP500.csv'))\n",
    "    data['^IXIC'].to_csv(os.path.join(DATA_DIR, 'Nasdaq.csv'))\n",
    "\n",
    "    print(\"Updated technical/price data.\")\n",
    "\n",
    "# 3. Sentiment/News Data (Finnhub)\n",
    "def update_sentiment():\n",
    "    api_key = os.environ.get('FINNHUB_KEY')\n",
    "    client = finnhub.Client(api_key=api_key)\n",
    "\n",
    "    DATA_FILE = '../data/clean_news_sentiment.csv'\n",
    "    TARGET_FROM_DATE = datetime(2025, 6, 26)\n",
    "    INITIAL_TO_DATE = datetime.today()  # Start from most recent\n",
    "\n",
    "    # Helper to get the last date in the CSV (as datetime), or return INITIAL_TO_DATE if file doesn't exist\n",
    "    def get_last_date():\n",
    "        if os.path.exists(DATA_FILE):\n",
    "            df = pd.read_csv(DATA_FILE)\n",
    "            if not df.empty:\n",
    "                min_date_str = df['date'].min()\n",
    "                return datetime.strptime(min_date_str, '%Y-%m-%d')\n",
    "        return INITIAL_TO_DATE\n",
    "\n",
    "    while True:\n",
    "        last_date = get_last_date()\n",
    "        if last_date <= TARGET_FROM_DATE:\n",
    "            print(\"All news up to target date fetched.\")\n",
    "            break\n",
    "\n",
    "        from_date = max(TARGET_FROM_DATE, last_date - timedelta(days=30))  # Fetch up to 30 days at a time\n",
    "        to_date = last_date\n",
    "\n",
    "        print(f\"Fetching news from {from_date.strftime('%Y-%m-%d')} to {to_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        news = client.company_news(\n",
    "            \"RBLX\",\n",
    "            _from=from_date.strftime(\"%Y-%m-%d\"),\n",
    "            to=to_date.strftime(\"%Y-%m-%d\")\n",
    "        )\n",
    "\n",
    "        if not news:\n",
    "            print(\"No more news to fetch.\")\n",
    "            break\n",
    "\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        results = []\n",
    "        for article in news:\n",
    "            text = (article.get(\"headline\", \"\") + \"\\n\" + article.get(\"summary\", \"\")).strip()\n",
    "            vs = sia.polarity_scores(text)\n",
    "            results.append({\n",
    "                \"date\": datetime.fromtimestamp(article[\"datetime\"]).strftime(\"%Y-%m-%d\"),\n",
    "                \"headline\": article[\"headline\"],\n",
    "                **vs\n",
    "            })\n",
    "        new_df = pd.DataFrame(results)\n",
    "\n",
    "        # If file exists, append, else just save new\n",
    "        if os.path.exists(DATA_FILE):\n",
    "            old_df = pd.read_csv(DATA_FILE)\n",
    "            combined_df = pd.concat([old_df, new_df], ignore_index=True)\n",
    "            combined_df.drop_duplicates(subset=[\"date\", \"headline\"], inplace=True)\n",
    "        else:\n",
    "            combined_df = new_df\n",
    "\n",
    "        combined_df.to_csv(DATA_FILE, index=False)\n",
    "        print(f\"Appended news from {from_date.strftime('%Y-%m-%d')} to {to_date.strftime('%Y-%m-%d')}.\")\n",
    "\n",
    "        # To avoid too many requests per minute; adjust as needed to respect API rate limits\n",
    "        import time\n",
    "        time.sleep(60)\n",
    "\n",
    "    print(\"Finished fetching all available news.\")\n",
    "\n",
    "\n",
    "# 4. User/Engagement Data (RoMonitor API)\n",
    "def update_romonitor():\n",
    "    # Always use UTC for timestamps in this API\n",
    "    today = datetime.now(timezone.utc).strftime('%Y-%m-%dT23:59:59.999Z')\n",
    "\n",
    "    endpoints = {\n",
    "        \"ccu\": f\"https://romonitorstats.com/api/v1/charts/get?name=platform-ccus&timeslice=day&start=2020-01-05T00:00:00.000Z&ends={today}\",\n",
    "        \"registrations\": f\"https://romonitorstats.com/api/v1/charts/get?name=platform-registrations&timeslice=day&start=2020-03-15T00:00:00.000Z&ends={today}\",\n",
    "        \"session_length\": f\"https://romonitorstats.com/api/v1/charts/get?name=platform-session-length&timeslice=day&start=2023-04-01T00:00:00.000Z&ends={today}\"\n",
    "    }\n",
    "    output_dir = os.path.join(\"../data/\", \"romonitor_data\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for key, url in endpoints.items():\n",
    "        df = pd.DataFrame(requests.get(url).json())\n",
    "        df.to_csv(os.path.join(output_dir, f\"{key}.csv\"), index=False)\n",
    "        print(f\"Updated {key} data from RoMonitor.\")\n",
    "\n",
    "# 5. Update and retrieve SEC data\n",
    "def update_sec_data():\n",
    "    dl = Downloader(\"RBLX_SEC\", \"saysaygo@gmail.com\", \"../data\")\n",
    "    CIK = \"RBLX\"\n",
    "\n",
    "    dl.get(\"10-K\", CIK, after=\"2021-01-01\")\n",
    "    dl.get(\"10-Q\", CIK, after=\"2021-01-01\")\n",
    "    dl.get(\"8-K\", CIK, after=\"2021-01-01\")\n",
    "\n",
    "    print(\"Updated SEC data\")\n",
    "\n",
    "# 6. Update Quarterly Financials\n",
    "def update_quarterly_financials():\n",
    "    rblx = yf.Ticker(\"RBLX\")\n",
    "\n",
    "    rblx.quarterly_financials.to_csv(DATA_DIR + \"RBLX_quarterly_income_statement.csv\")\n",
    "    rblx.quarterly_balance_sheet.to_csv(DATA_DIR + \"RBLX_quarterly_balance_sheet.csv\")\n",
    "    rblx.quarterly_cashflow.to_csv(DATA_DIR + \"RBLX_quarterly_cashflow.csv\")\n",
    "\n",
    "    print(\"Updated Quarterly Financials\")\n",
    "    \n",
    "def update_trends_data_daily_merged(max_retries=5, wait_seconds=60):\n",
    "    \"\"\"\n",
    "    Downloads daily Google Trends data for 'Roblox' (web & news search)\n",
    "    from 2021-03-10 to today, merges by date, and saves as a single CSV\n",
    "    in YYYY-MM-DD format (e.g., 2021-03-31).\n",
    "    \"\"\"\n",
    "    pytrends = TrendReq(hl='en-US', tz=360)\n",
    "    kw_list = [\"Roblox\"]\n",
    "    start_date = datetime(2021, 3, 10)\n",
    "    end_date = datetime.today()\n",
    "    window = timedelta(days=89)  # 90 days\n",
    "\n",
    "    def get_trends(gprop, colname):\n",
    "        all_data = []\n",
    "        curr_start = start_date\n",
    "        while curr_start < end_date:\n",
    "            curr_end = min(curr_start + window, end_date)\n",
    "            timeframe = f\"{curr_start.strftime('%Y-%m-%d')} {curr_end.strftime('%Y-%m-%d')}\"\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    pytrends.build_payload(kw_list, timeframe=timeframe, geo='', gprop=gprop)\n",
    "                    df = pytrends.interest_over_time()\n",
    "                    if df.empty:\n",
    "                        print(f\"No data for {colname} window {timeframe}. Skipping.\")\n",
    "                        break\n",
    "                    if 'isPartial' in df.columns:\n",
    "                        df = df.drop(columns=['isPartial'])\n",
    "                    df = df.reset_index()\n",
    "                    # Format as YYYY-MM-DD\n",
    "                    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "                    df = df.rename(columns={'Roblox': colname})\n",
    "                    df = df[['date', colname]]\n",
    "                    all_data.append(df)\n",
    "                    print(f\"Fetched daily {colname} data for {timeframe}\")\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(f\"Error on {colname} {timeframe}: {e}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        print(f\"Retrying in {wait_seconds} seconds...\")\n",
    "                        time.sleep(wait_seconds)\n",
    "                    else:\n",
    "                        print(f\"Giving up on {colname} window.\")\n",
    "            curr_start = curr_end + timedelta(days=1)\n",
    "        if all_data:\n",
    "            combined = pd.concat(all_data).drop_duplicates('date').sort_values('date')\n",
    "            return combined\n",
    "        else:\n",
    "            print(f\"No {colname} data retrieved.\")\n",
    "            return pd.DataFrame(columns=['date', colname])\n",
    "\n",
    "    web_df = get_trends('', 'roblox_trend_web')\n",
    "    news_df = get_trends('news', 'roblox_trend_news')\n",
    "\n",
    "    merged = pd.merge(web_df, news_df, on='date', how='outer').sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    out_path = os.path.join(DATA_DIR, 'roblox_trends_merged_daily.csv')\n",
    "    merged.to_csv(out_path, index=False)\n",
    "    print(f\"Saved merged daily Google Trends data for Roblox at {out_path}\")"
   ],
   "id": "80bef6fa5546fd1c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:28.918629Z",
     "start_time": "2025-07-17T01:40:56.868590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "update_market_context()\n",
    "update_technical()\n",
    "update_sentiment()\n",
    "update_romonitor()\n",
    "#update_sec_data()\n",
    "update_trends_data_daily_merged()\n",
    "print(\"All data updated!\")"
   ],
   "id": "9c718c07b0245725",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated market context data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated technical/price data.\n",
      "Updated ccu data from RoMonitor.\n",
      "Updated registrations data from RoMonitor.\n",
      "Updated session_length data from RoMonitor.\n",
      "Fetched daily roblox_trend_web data for 2021-03-10 2021-06-07\n",
      "Fetched daily roblox_trend_web data for 2021-06-08 2021-09-05\n",
      "Fetched daily roblox_trend_web data for 2021-09-06 2021-12-04\n",
      "Fetched daily roblox_trend_web data for 2021-12-05 2022-03-04\n",
      "Fetched daily roblox_trend_web data for 2022-03-05 2022-06-02\n",
      "Fetched daily roblox_trend_web data for 2022-06-03 2022-08-31\n",
      "Fetched daily roblox_trend_web data for 2022-09-01 2022-11-29\n",
      "Fetched daily roblox_trend_web data for 2022-11-30 2023-02-27\n",
      "Fetched daily roblox_trend_web data for 2023-02-28 2023-05-28\n",
      "Fetched daily roblox_trend_web data for 2023-05-29 2023-08-26\n",
      "Fetched daily roblox_trend_web data for 2023-08-27 2023-11-24\n",
      "Fetched daily roblox_trend_web data for 2023-11-25 2024-02-22\n",
      "Fetched daily roblox_trend_web data for 2024-02-23 2024-05-22\n",
      "Fetched daily roblox_trend_web data for 2024-05-23 2024-08-20\n",
      "Fetched daily roblox_trend_web data for 2024-08-21 2024-11-18\n",
      "Fetched daily roblox_trend_web data for 2024-11-19 2025-02-16\n",
      "Fetched daily roblox_trend_web data for 2025-02-17 2025-05-17\n",
      "Fetched daily roblox_trend_web data for 2025-05-18 2025-07-16\n",
      "Fetched daily roblox_trend_news data for 2021-03-10 2021-06-07\n",
      "Fetched daily roblox_trend_news data for 2021-06-08 2021-09-05\n",
      "Fetched daily roblox_trend_news data for 2021-09-06 2021-12-04\n",
      "Fetched daily roblox_trend_news data for 2021-12-05 2022-03-04\n",
      "Fetched daily roblox_trend_news data for 2022-03-05 2022-06-02\n",
      "Fetched daily roblox_trend_news data for 2022-06-03 2022-08-31\n",
      "Fetched daily roblox_trend_news data for 2022-09-01 2022-11-29\n",
      "Fetched daily roblox_trend_news data for 2022-11-30 2023-02-27\n",
      "Fetched daily roblox_trend_news data for 2023-02-28 2023-05-28\n",
      "Fetched daily roblox_trend_news data for 2023-05-29 2023-08-26\n",
      "Fetched daily roblox_trend_news data for 2023-08-27 2023-11-24\n",
      "Fetched daily roblox_trend_news data for 2023-11-25 2024-02-22\n",
      "Fetched daily roblox_trend_news data for 2024-02-23 2024-05-22\n",
      "Fetched daily roblox_trend_news data for 2024-05-23 2024-08-20\n",
      "Fetched daily roblox_trend_news data for 2024-08-21 2024-11-18\n",
      "Fetched daily roblox_trend_news data for 2024-11-19 2025-02-16\n",
      "Fetched daily roblox_trend_news data for 2025-02-17 2025-05-17\n",
      "Fetched daily roblox_trend_news data for 2025-05-18 2025-07-16\n",
      "Saved merged daily Google Trends data for Roblox at ../data/roblox_trends_merged_daily.csv\n",
      "All data updated!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Just In-case update_sentiment doesn't work :)",
   "id": "2009aec7d080a3b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:50.446337Z",
     "start_time": "2025-07-17T01:41:28.963771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime, time, random, urllib.parse, requests, feedparser, pandas as pd\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from email.utils import parsedate_to_datetime\n",
    "\n",
    "BASE = \"https://news.google.com/rss/search\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_6_1) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/125.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept\": \"application/rss+xml, text/xml;q=0.9\",\n",
    "}\n",
    "\n",
    "def month_slices(start, end):\n",
    "    d = datetime.date(start.year, start.month, 1)\n",
    "    while d <= end:\n",
    "        nxt = (d.replace(day=28) + datetime.timedelta(days=4)).replace(day=1)\n",
    "        yield d, min(nxt - datetime.timedelta(days=1), end)\n",
    "        d = nxt\n",
    "\n",
    "def build_url(keywords, since, until):\n",
    "    q = f'{keywords} after:{since} before:{(until + datetime.timedelta(days=1))}'\n",
    "    params = {\"q\": q, \"hl\": \"en-US\", \"gl\": \"US\", \"ceid\": \"US:en\"}\n",
    "    return f\"{BASE}?{urllib.parse.urlencode(params, quote_via=urllib.parse.quote_plus)}\"\n",
    "\n",
    "def session(max_retries=5):\n",
    "    s = requests.Session()\n",
    "    rs = Retry(total=max_retries, backoff_factor=1,\n",
    "               status_forcelist=[429, 500, 502, 503, 504])\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=rs))\n",
    "    s.headers.update(HEADERS)\n",
    "    return s\n",
    "\n",
    "def fetch_month(url, sess):\n",
    "    for _ in range(2):                          # up to 1 retry on 503\n",
    "        r = sess.get(url, timeout=15)\n",
    "        if r.status_code == 200:\n",
    "            return feedparser.parse(r.text).entries\n",
    "        if r.status_code == 503:\n",
    "            time.sleep(60)                      # hard back-off\n",
    "    raise RuntimeError(f\"Still 503 → {url}\")\n",
    "\n",
    "def scrape(keywords, start, end, outfile):\n",
    "    sia, rows, sess = SentimentIntensityAnalyzer(), [], session()\n",
    "    for since, until in month_slices(start, end):\n",
    "        url = build_url(keywords, since, until)\n",
    "        for e in fetch_month(url, sess):\n",
    "            score = sia.polarity_scores(e.title)\n",
    "            rows.append({\n",
    "                \"date\": parsedate_to_datetime(e.published).strftime(\"%Y-%m-%d\"),\n",
    "                \"headline\": e.title, \n",
    "                **score\n",
    "            })\n",
    "        time.sleep(random.uniform(6, 12))       # polite spacing\n",
    "\n",
    "    new_df = pd.DataFrame(rows)\n",
    "\n",
    "    # Check if file exists\n",
    "    if os.path.exists(outfile):\n",
    "        old_df = pd.read_csv(outfile)\n",
    "        # Combine new data on top of old data\n",
    "        combined_df = pd.concat([new_df, old_df], ignore_index=True)\n",
    "        # Drop duplicates (by date+headline, keep first occurrence)\n",
    "        combined_df.drop_duplicates(subset=[\"date\", \"headline\"], keep=\"first\", inplace=True)\n",
    "    else:\n",
    "        combined_df = new_df\n",
    "\n",
    "    # Sort so latest date is on top\n",
    "    combined_df[\"date\"] = pd.to_datetime(combined_df[\"date\"])\n",
    "    combined_df.sort_values(by=\"date\", ascending=False, inplace=True)\n",
    "    combined_df.to_csv(outfile, index=False)\n",
    "    print(f\"Saved {len(combined_df)} rows → {outfile}\")\n",
    "\n",
    "# -------- run --------\n",
    "ipo  = datetime.date(2025, 6, 23)\n",
    "today = datetime.date.today()\n",
    "scrape(\"RBLX stock\", ipo, today, \"../data/clean_news_sentiment.csv\")"
   ],
   "id": "73aa8073cd09eeab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2366 rows → ../data/clean_news_sentiment.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Cleaning Part 1",
   "id": "a8207cbb268bc5d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:50.860102Z",
     "start_time": "2025-07-17T01:41:50.493918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "\n",
    "from bs4.diagnose import lxml_trace\n",
    "\n",
    "DATA_DIR = \"../data/romonitor_data/\"\n",
    "OUTPUT_DIR = \"../data/romonitor_data_clean/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_timeseries_from_data(file, value_colname):\n",
    "    df = pd.read_csv(DATA_DIR + file)\n",
    "    # Only keep rows with a real 'name' (not metadata)\n",
    "    df = df[df['name'].notna()]\n",
    "    # Parse the dict in 'data'\n",
    "    data_dict = ast.literal_eval(df.iloc[0]['data'])\n",
    "    # Convert to DataFrame\n",
    "    ts_df = pd.DataFrame(list(data_dict.items()), columns=['date', value_colname])\n",
    "    ts_df['date'] = pd.to_datetime(ts_df['date']).dt.strftime('%Y-%m-%d')\n",
    "    ts_df = ts_df.sort_values('date').reset_index(drop=True)\n",
    "    ts_df.to_csv(OUTPUT_DIR + value_colname + '.csv', index=False)\n",
    "    print(f\"Saved: {OUTPUT_DIR}{value_colname}.csv\")\n",
    "    return ts_df\n",
    "\n",
    "def extract_and_sum_popular_games():\n",
    "    df = pd.read_csv(DATA_DIR + 'popular_games.csv')\n",
    "    df = df[df['name'].notna()]\n",
    "    game_dfs = []\n",
    "    for _, row in df.iterrows():\n",
    "        data_raw = row['data']\n",
    "        try:\n",
    "            data_dict = ast.literal_eval(data_raw)\n",
    "        except:\n",
    "            continue  \n",
    "        if isinstance(data_dict, dict):\n",
    "            game_df = pd.DataFrame(list(data_dict.items()), columns=['date', 'value'])\n",
    "            game_df['date'] = pd.to_datetime(game_df['date'])\n",
    "            game_dfs.append(game_df)\n",
    "    if not game_dfs:\n",
    "        print(\"No games with usable data found!\")\n",
    "        return None\n",
    "    all_games = pd.concat(game_dfs)\n",
    "    sum_games = all_games.groupby(all_games['date'].dt.strftime('%Y-%m-%d'))['value'].sum().reset_index()\n",
    "    sum_games = sum_games.rename(columns={'value': 'popular_games_total'})\n",
    "    sum_games.to_csv(OUTPUT_DIR + 'popular_games_total.csv', index=False)\n",
    "    print(f\"Saved: {OUTPUT_DIR}popular_games_total.csv\")\n",
    "    return sum_games\n",
    "\n",
    "# Clean and save time series\n",
    "extract_timeseries_from_data('ccu.csv', 'ccu')\n",
    "extract_timeseries_from_data('registrations.csv', 'registrations')\n",
    "extract_timeseries_from_data('session_length.csv', 'session_length')\n",
    "extract_and_sum_popular_games()"
   ],
   "id": "2f4900e0d3576996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/romonitor_data_clean/ccu.csv\n",
      "Saved: ../data/romonitor_data_clean/registrations.csv\n",
      "Saved: ../data/romonitor_data_clean/session_length.csv\n",
      "Saved: ../data/romonitor_data_clean/popular_games_total.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          date  popular_games_total\n",
       "0   2025-05-06           79758549.0\n",
       "1   2025-05-07           79997871.0\n",
       "2   2025-05-08           81165810.0\n",
       "3   2025-05-09           89288600.0\n",
       "4   2025-05-10          116785967.0\n",
       "5   2025-05-11          114392357.0\n",
       "6   2025-05-12           79589010.0\n",
       "7   2025-05-13           75347467.0\n",
       "8   2025-05-14           75645524.0\n",
       "9   2025-05-15           75085390.0\n",
       "10  2025-05-16           77687171.0\n",
       "11  2025-05-17          108026313.0\n",
       "12  2025-05-18          108439485.0\n",
       "13  2025-05-19           75299253.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>popular_games_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>79758549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>79997871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>81165810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>89288600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-10</td>\n",
       "      <td>116785967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>114392357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>79589010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>75347467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>75645524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>75085390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>77687171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>108026313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>108439485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>75299253.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:50.972732Z",
     "start_time": "2025-07-17T01:41:50.895659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_quarterly_fundamental(filepath, prefix=None):\n",
    "    # Load and transpose so dates are rows, metrics are columns\n",
    "    df = pd.read_csv(filepath, index_col=0).transpose()\n",
    "\n",
    "    df = df.reset_index().rename(columns={'index': 'date'})\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    if prefix:\n",
    "        newcols = ['date'] + [f\"{prefix}{col}\" for col in df.columns if col != 'date']\n",
    "        df.columns = newcols\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# EXAMPLES:\n",
    "# Cleaned income statement\n",
    "qis = clean_quarterly_fundamental(\"../data/RBLX_quarterly_income_statement.csv\", prefix=\"qis_\")\n",
    "qis.to_csv(\"../data/cleaned_quarterly_income_statement.csv\", index=False)\n",
    "\n",
    "# Cleaned balance sheet\n",
    "qbs = clean_quarterly_fundamental(\"../data/RBLX_quarterly_balance_sheet.csv\", prefix=\"qbs_\")\n",
    "qbs.to_csv(\"../data/cleaned_quarterly_balance_sheet.csv\", index=False)\n",
    "\n",
    "# Cleaned cash flow\n",
    "qcf = clean_quarterly_fundamental(\"../data/RBLX_quarterly_cashflow.csv\", prefix=\"qcf_\")\n",
    "qcf.to_csv(\"../data/cleaned_quarterly_cashflow.csv\", index=False)"
   ],
   "id": "346ec6b51fb934f5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T06:37:14.053390Z",
     "start_time": "2025-07-03T06:37:13.636928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parsing and extracting SEC file data\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import textstat\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# --- Load Loughran-McDonald financial sentiment dictionary ---\n",
    "def load_lm_dicts(lm_dict_path):\n",
    "    lm_df = pd.read_csv(lm_dict_path)\n",
    "    lm_negative = set(lm_df[lm_df['Negative'] > 0]['Word'].str.lower())\n",
    "    lm_positive = set(lm_df[lm_df['Positive'] > 0]['Word'].str.lower())\n",
    "    return lm_negative, lm_positive\n",
    "\n",
    "def extract_filing_date_from_txt(raw_txt):\n",
    "    # Look for the \"FILED AS OF DATE:\" line and extract date\n",
    "    match = re.search(r'FILED AS OF DATE:\\s+(\\d{8})', raw_txt)\n",
    "    if match:\n",
    "        # Format as YYYY-MM-DD\n",
    "        date_str = match.group(1)\n",
    "        return f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "    return \"\"  # fallback if not found\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags, non-letters, numbers, extra whitespace\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def compute_lm_sentiment(tokens, neg_words, pos_words):\n",
    "    tokens = [t.lower() for t in tokens if len(t) > 1]\n",
    "    n_pos = sum(1 for t in tokens if t in pos_words)\n",
    "    n_neg = sum(1 for t in tokens if t in neg_words)\n",
    "    if n_pos + n_neg == 0:\n",
    "        return 0\n",
    "    return (n_pos - n_neg) / (n_pos + n_neg)\n",
    "\n",
    "def extract_date_and_type(filename):\n",
    "    # Try to extract date (YYYY-MM-DD or YYYYMMDD) and form type from filename or path\n",
    "    date_match = re.search(r'(\\d{4}-\\d{2}-\\d{2})', filename)\n",
    "    if not date_match:\n",
    "        date_match = re.search(r'(\\d{8})', filename)\n",
    "        if date_match:\n",
    "            # Convert YYYYMMDD to YYYY-MM-DD\n",
    "            date_str = date_match.group(1)\n",
    "            date = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "        else:\n",
    "            date = \"\"\n",
    "    else:\n",
    "        date = date_match.group(1)\n",
    "    # Form type: look for 10-K, 10-Q, 8-K in path or filename\n",
    "    type_match = re.search(r'(10[-\\s]?K|10[-\\s]?Q|8[-\\s]?K)', filename, re.IGNORECASE)\n",
    "    form_type = type_match.group(1).upper().replace(' ', '').replace('-', '') if type_match else \"\"\n",
    "    return date, form_type\n",
    "\n",
    "def process_filing(filepath, neg_words, pos_words):\n",
    "    basename = os.path.basename(filepath)\n",
    "    with open(filepath, encoding='utf-8', errors='ignore') as f:\n",
    "        raw = f.read()\n",
    "    filing_date = extract_filing_date_from_txt(raw)\n",
    "    form_type = extract_date_and_type(filepath)[1]\n",
    "    text = clean_text(raw)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w.lower() not in stopwords.words('english')]\n",
    "    try:\n",
    "        fog = textstat.gunning_fog(text)\n",
    "    except Exception:\n",
    "        fog = None\n",
    "    return {\n",
    "        'date': filing_date,\n",
    "        'form_type': form_type,\n",
    "        'filename': basename,\n",
    "        'fog_index': fog,\n",
    "    }\n",
    "\n",
    "def process_all_filings(folder, lm_dict_path, out_csv):\n",
    "    neg_words, pos_words = load_lm_dicts(lm_dict_path)\n",
    "    results = []\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for fname in files:\n",
    "            if fname.endswith('.txt'):\n",
    "                filepath = os.path.join(root, fname)\n",
    "                summary = process_filing(filepath, neg_words, pos_words)\n",
    "                results.append(summary)\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Saved SEC filings features to {out_csv}\")\n",
    "    return df"
   ],
   "id": "e61a03833446e72d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\saysa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saysa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T06:39:33.391031Z",
     "start_time": "2025-07-03T06:39:17.537024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEC_FOLDER = \"../data/sec-edgar-filings/\"\n",
    "LM_DICT_PATH = \"../data/Loughran-McDonald_MasterDictionary_1993-2024.csv\"\n",
    "OUT_CSV = \"../data/sec_filings_features.csv\"\n",
    "process_all_filings(SEC_FOLDER, LM_DICT_PATH, OUT_CSV)"
   ],
   "id": "a8a1a9ef44e08469",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m LM_DICT_PATH = \u001B[33m\"\u001B[39m\u001B[33m../data/Loughran-McDonald_MasterDictionary_1993-2024.csv\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      3\u001B[39m OUT_CSV = \u001B[33m\"\u001B[39m\u001B[33m../data/sec_filings_features.csv\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m \u001B[43mprocess_all_filings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mSEC_FOLDER\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mLM_DICT_PATH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mOUT_CSV\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 95\u001B[39m, in \u001B[36mprocess_all_filings\u001B[39m\u001B[34m(folder, lm_dict_path, out_csv)\u001B[39m\n\u001B[32m     93\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m fname.endswith(\u001B[33m'\u001B[39m\u001B[33m.txt\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m     94\u001B[39m             filepath = os.path.join(root, fname)\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m             summary = \u001B[43mprocess_filing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneg_words\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_words\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m             results.append(summary)\n\u001B[32m     97\u001B[39m df = pd.DataFrame(results)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 74\u001B[39m, in \u001B[36mprocess_filing\u001B[39m\u001B[34m(filepath, neg_words, pos_words)\u001B[39m\n\u001B[32m     72\u001B[39m text = clean_text(raw)\n\u001B[32m     73\u001B[39m tokens = word_tokenize(text)\n\u001B[32m---> \u001B[39m\u001B[32m74\u001B[39m tokens = [w \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m tokens \u001B[38;5;28;01mif\u001B[39;00m w.lower() \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[43mstopwords\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43menglish\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m]\n\u001B[32m     75\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     76\u001B[39m     fog = textstat.gunning_fog(text)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\QuantumAlgo\\.venv\\Lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001B[39m, in \u001B[36mWordListCorpusReader.words\u001B[39m\u001B[34m(self, fileids, ignore_lines_startswith)\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwords\u001B[39m(\u001B[38;5;28mself\u001B[39m, fileids=\u001B[38;5;28;01mNone\u001B[39;00m, ignore_lines_startswith=\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[32m     20\u001B[39m         line\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m line_tokenize(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfileids\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     22\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line.startswith(ignore_lines_startswith)\n\u001B[32m     23\u001B[39m     ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\QuantumAlgo\\.venv\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001B[39m, in \u001B[36mCorpusReader.raw\u001B[39m\u001B[34m(self, fileids)\u001B[39m\n\u001B[32m    216\u001B[39m contents = []\n\u001B[32m    217\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m fileids:\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m fp:\n\u001B[32m    219\u001B[39m         contents.append(fp.read())\n\u001B[32m    220\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m concat(contents)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\QuantumAlgo\\.venv\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001B[39m, in \u001B[36mCorpusReader.open\u001B[39m\u001B[34m(self, file)\u001B[39m\n\u001B[32m    223\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    224\u001B[39m \u001B[33;03mReturn an open stream that can be used to read the given file.\u001B[39;00m\n\u001B[32m    225\u001B[39m \u001B[33;03mIf the file's encoding is not None, then the stream will\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    228\u001B[39m \u001B[33;03m:param file: The file identifier of the file to read.\u001B[39;00m\n\u001B[32m    229\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    230\u001B[39m encoding = \u001B[38;5;28mself\u001B[39m.encoding(file)\n\u001B[32m--> \u001B[39m\u001B[32m231\u001B[39m stream = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_root\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    232\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m stream\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\QuantumAlgo\\.venv\\Lib\\site-packages\\nltk\\data.py:323\u001B[39m, in \u001B[36mFileSystemPathPointer.open\u001B[39m\u001B[34m(self, encoding)\u001B[39m\n\u001B[32m    322\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m, encoding=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m323\u001B[39m     stream = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    324\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m encoding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    325\u001B[39m         stream = SeekableUnicodeStreamReader(stream, encoding)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:52.592019Z",
     "start_time": "2025-07-17T01:41:51.002594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge All the data together\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_date_column(df):\n",
    "    # Rename any column with 'date' (case-insensitive) to 'date'\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'date':\n",
    "            df = df.rename(columns={col: 'date'})\n",
    "            break\n",
    "    return df\n",
    "\n",
    "def move_to_monday(date):\n",
    "    if date.weekday() == 5:  # Saturday\n",
    "        return date + pd.Timedelta(days=2)\n",
    "    elif date.weekday() == 6:  # Sunday\n",
    "        return date + pd.Timedelta(days=1)\n",
    "    else:\n",
    "        return date\n",
    "\n",
    "# --- Load Data ---\n",
    "stock = pd.read_csv(\"../data/RBLX_with_technicals.csv\")\n",
    "sp500 = pd.read_csv(\"../data/SP500.csv\")\n",
    "nasdaq = pd.read_csv(\"../data/Nasdaq.csv\")\n",
    "popular_games_total = pd.read_csv(\"../data/romonitor_data_clean/popular_games_total.csv\")\n",
    "registrations = pd.read_csv(\"../data/romonitor_data_clean/registrations.csv\")\n",
    "ccu = pd.read_csv(\"../data/romonitor_data_clean/ccu.csv\")\n",
    "session_length = pd.read_csv(\"../data/romonitor_data_clean/session_length.csv\")\n",
    "sentiment = pd.read_csv(\"../data/clean_news_sentiment.csv\")\n",
    "market = pd.read_csv(\"../data/market_context_data.csv\")\n",
    "trends = pd.read_csv(\"../data/roblox_trends_merged_daily.csv\")\n",
    "sec = pd.read_csv(\"../data/sec_filings_features.csv\")\n",
    "qbs = pd.read_csv(\"../data/cleaned_quarterly_balance_sheet.csv\")\n",
    "qcf = pd.read_csv(\"../data/cleaned_quarterly_cashflow.csv\")\n",
    "qis = pd.read_csv(\"../data/cleaned_quarterly_income_statement.csv\")\n",
    "\n",
    "# --- Standardize Columns and Dates ---\n",
    "sp500 = standardize_date_column(sp500)\n",
    "nasdaq = standardize_date_column(nasdaq)\n",
    "sp500 = sp500.rename(columns={col: f\"SP500_{col}\" for col in sp500.columns if col != \"date\"})\n",
    "nasdaq = nasdaq.rename(columns={col: f\"Nasdaq_{col}\" for col in nasdaq.columns if col != \"date\"})\n",
    "\n",
    "# --- Aggregating sentiment scores ---\n",
    "sentiment['date'] = pd.to_datetime(sentiment['date'], errors='coerce')\n",
    "sentiment['date'] = sentiment['date'].apply(move_to_monday)\n",
    "sentiment = sentiment.groupby('date', as_index=False)[['neg', 'neu', 'pos', 'compound']].mean()\n",
    "\n",
    "trends['date'] = pd.to_datetime(trends['date'], errors='coerce')\n",
    "trends['date'] = trends['date'].apply(move_to_monday)\n",
    "trends = trends.groupby('date', as_index=False)[['roblox_trend_web', 'roblox_trend_news']].mean()\n",
    "\n",
    "\n",
    "dfs = [\n",
    "    stock, sp500, nasdaq, popular_games_total, registrations,\n",
    "    ccu, session_length, sentiment, trends, market, sec\n",
    "]\n",
    "dfs = [standardize_date_column(df) for df in dfs]\n",
    "\n",
    "# Add quarterly dfs to standardize and convert dates too (but don't merge yet)\n",
    "quarterly_dfs = [qbs, qcf, qis]\n",
    "quarterly_dfs = [standardize_date_column(df) for df in quarterly_dfs]\n",
    "\n",
    "# Ensure all 'date' columns are datetime type\n",
    "for df in dfs + quarterly_dfs:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# --- Merge All Daily DataFrames ---\n",
    "master = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    master = master.merge(df, on='date', how='outer')\n",
    "\n",
    "# --- Forward-fill Quarterly Data to Daily Rows ---\n",
    "for quarterly_df in quarterly_dfs:\n",
    "    quarterly_df = quarterly_df.sort_values('date')\n",
    "    master = pd.merge_asof(master.sort_values('date'), quarterly_df, on='date', direction='backward')\n",
    "\n",
    "# --- Filter to IPO date or later ---\n",
    "ipo_date = pd.to_datetime(\"2021-03-10\")\n",
    "master = master[master[\"date\"] >= ipo_date]\n",
    "\n",
    "# --- Final Touches ---\n",
    "master = master.sort_values('date').reset_index(drop=True)\n",
    "master.to_csv(\"../data/master_dataset.csv\", index=False)\n",
    "print(\"Master dataset saved as master_dataset.csv (with quarterly features forward-filled)\")"
   ],
   "id": "c0a9c2f85e4f6763",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset saved as master_dataset.csv (with quarterly features forward-filled)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Cleaning Part 2",
   "id": "2498c80dc959ff6e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:52.697306Z",
     "start_time": "2025-07-17T01:41:52.618695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "master = pd.read_csv(\"../data/master_dataset.csv\")"
   ],
   "id": "6cd1bca4100dcf83",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:52.748907Z",
     "start_time": "2025-07-17T01:41:52.722905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Drop rows where the market is closed (no stock price)\n",
    "master = master[master['Close'].notna()].copy()\n",
    "\n",
    "master"
   ],
   "id": "616470a48a950d5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date        Open        High         Low       Close      Volume  \\\n",
       "0     2021-03-10   64.500000   74.830002   60.500000   69.500000  97069300.0   \n",
       "1     2021-03-11   74.930000   77.779999   70.129997   73.900002  59629300.0   \n",
       "2     2021-03-12   72.470001   72.959999   69.110001   69.699997  19714700.0   \n",
       "5     2021-03-15   70.019997   74.059998   66.250000   72.150002  19549800.0   \n",
       "6     2021-03-16   73.730003   78.000000   73.180000   77.000000  30274400.0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1591  2025-07-10  106.900002  107.370003  102.730003  105.029999   5636700.0   \n",
       "1592  2025-07-11  104.949997  108.099998  104.809998  105.690002   4544500.0   \n",
       "1595  2025-07-14  106.349998  111.959999  106.349998  111.830002   8032300.0   \n",
       "1596  2025-07-15  110.610001  113.070000  110.209999  112.480003   8105900.0   \n",
       "1597  2025-07-16  112.400002  120.160004  112.230003  119.019997  15276300.0   \n",
       "\n",
       "       SP500_Open   SP500_High    SP500_Low  SP500_Close  ...  \\\n",
       "0     3891.989990  3917.350098  3885.729980  3898.810059  ...   \n",
       "1     3915.540039  3960.270020  3915.540039  3939.340088  ...   \n",
       "2     3924.520020  3944.989990  3915.209961  3943.340088  ...   \n",
       "5     3942.959961  3970.080078  3923.540039  3968.939941  ...   \n",
       "6     3973.590088  3981.040039  3953.439941  3962.709961  ...   \n",
       "...           ...          ...          ...          ...  ...   \n",
       "1591  6266.799805  6290.220215  6251.439941  6280.459961  ...   \n",
       "1592  6255.680176  6269.439941  6237.600098  6259.750000  ...   \n",
       "1595  6255.149902  6273.310059  6239.220215  6268.560059  ...   \n",
       "1596  6295.290039  6302.040039  6241.680176  6243.759766  ...   \n",
       "1597  6254.500000  6268.120117  6201.589844  6263.700195  ...   \n",
       "\n",
       "      qis_Other Operating Expenses  qis_Research And Development  \\\n",
       "0                              NaN                           NaN   \n",
       "1                              NaN                           NaN   \n",
       "2                              NaN                           NaN   \n",
       "5                              NaN                           NaN   \n",
       "6                              NaN                           NaN   \n",
       "...                            ...                           ...   \n",
       "1591                   523691000.0                   374600000.0   \n",
       "1592                   523691000.0                   374600000.0   \n",
       "1595                   523691000.0                   374600000.0   \n",
       "1596                   523691000.0                   374600000.0   \n",
       "1597                   523691000.0                   374600000.0   \n",
       "\n",
       "      qis_Selling General And Administration  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "5                                        NaN   \n",
       "6                                        NaN   \n",
       "...                                      ...   \n",
       "1591                             166900000.0   \n",
       "1592                             166900000.0   \n",
       "1595                             166900000.0   \n",
       "1596                             166900000.0   \n",
       "1597                             166900000.0   \n",
       "\n",
       "      qis_Selling And Marketing Expense  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "5                                   NaN   \n",
       "6                                   NaN   \n",
       "...                                 ...   \n",
       "1591                         47768000.0   \n",
       "1592                         47768000.0   \n",
       "1595                         47768000.0   \n",
       "1596                         47768000.0   \n",
       "1597                         47768000.0   \n",
       "\n",
       "      qis_General And Administrative Expense  qis_Other Gand A  \\\n",
       "0                                        NaN               NaN   \n",
       "1                                        NaN               NaN   \n",
       "2                                        NaN               NaN   \n",
       "5                                        NaN               NaN   \n",
       "6                                        NaN               NaN   \n",
       "...                                      ...               ...   \n",
       "1591                             119132000.0       119132000.0   \n",
       "1592                             119132000.0       119132000.0   \n",
       "1595                             119132000.0       119132000.0   \n",
       "1596                             119132000.0       119132000.0   \n",
       "1597                             119132000.0       119132000.0   \n",
       "\n",
       "      qis_Gross Profit  qis_Cost Of Revenue  qis_Total Revenue  \\\n",
       "0                  NaN                  NaN                NaN   \n",
       "1                  NaN                  NaN                NaN   \n",
       "2                  NaN                  NaN                NaN   \n",
       "5                  NaN                  NaN                NaN   \n",
       "6                  NaN                  NaN                NaN   \n",
       "...                ...                  ...                ...   \n",
       "1591       810482000.0          224725000.0       1.035207e+09   \n",
       "1592       810482000.0          224725000.0       1.035207e+09   \n",
       "1595       810482000.0          224725000.0       1.035207e+09   \n",
       "1596       810482000.0          224725000.0       1.035207e+09   \n",
       "1597       810482000.0          224725000.0       1.035207e+09   \n",
       "\n",
       "      qis_Operating Revenue  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "5                       NaN  \n",
       "6                       NaN  \n",
       "...                     ...  \n",
       "1591           1.035207e+09  \n",
       "1592           1.035207e+09  \n",
       "1595           1.035207e+09  \n",
       "1596           1.035207e+09  \n",
       "1597           1.035207e+09  \n",
       "\n",
       "[1101 rows x 198 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SP500_Open</th>\n",
       "      <th>SP500_High</th>\n",
       "      <th>SP500_Low</th>\n",
       "      <th>SP500_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>qis_Other Operating Expenses</th>\n",
       "      <th>qis_Research And Development</th>\n",
       "      <th>qis_Selling General And Administration</th>\n",
       "      <th>qis_Selling And Marketing Expense</th>\n",
       "      <th>qis_General And Administrative Expense</th>\n",
       "      <th>qis_Other Gand A</th>\n",
       "      <th>qis_Gross Profit</th>\n",
       "      <th>qis_Cost Of Revenue</th>\n",
       "      <th>qis_Total Revenue</th>\n",
       "      <th>qis_Operating Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>97069300.0</td>\n",
       "      <td>3891.989990</td>\n",
       "      <td>3917.350098</td>\n",
       "      <td>3885.729980</td>\n",
       "      <td>3898.810059</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>74.930000</td>\n",
       "      <td>77.779999</td>\n",
       "      <td>70.129997</td>\n",
       "      <td>73.900002</td>\n",
       "      <td>59629300.0</td>\n",
       "      <td>3915.540039</td>\n",
       "      <td>3960.270020</td>\n",
       "      <td>3915.540039</td>\n",
       "      <td>3939.340088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>72.470001</td>\n",
       "      <td>72.959999</td>\n",
       "      <td>69.110001</td>\n",
       "      <td>69.699997</td>\n",
       "      <td>19714700.0</td>\n",
       "      <td>3924.520020</td>\n",
       "      <td>3944.989990</td>\n",
       "      <td>3915.209961</td>\n",
       "      <td>3943.340088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>70.019997</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>72.150002</td>\n",
       "      <td>19549800.0</td>\n",
       "      <td>3942.959961</td>\n",
       "      <td>3970.080078</td>\n",
       "      <td>3923.540039</td>\n",
       "      <td>3968.939941</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>73.730003</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>73.180000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>30274400.0</td>\n",
       "      <td>3973.590088</td>\n",
       "      <td>3981.040039</td>\n",
       "      <td>3953.439941</td>\n",
       "      <td>3962.709961</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>106.900002</td>\n",
       "      <td>107.370003</td>\n",
       "      <td>102.730003</td>\n",
       "      <td>105.029999</td>\n",
       "      <td>5636700.0</td>\n",
       "      <td>6266.799805</td>\n",
       "      <td>6290.220215</td>\n",
       "      <td>6251.439941</td>\n",
       "      <td>6280.459961</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>104.949997</td>\n",
       "      <td>108.099998</td>\n",
       "      <td>104.809998</td>\n",
       "      <td>105.690002</td>\n",
       "      <td>4544500.0</td>\n",
       "      <td>6255.680176</td>\n",
       "      <td>6269.439941</td>\n",
       "      <td>6237.600098</td>\n",
       "      <td>6259.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>106.349998</td>\n",
       "      <td>111.959999</td>\n",
       "      <td>106.349998</td>\n",
       "      <td>111.830002</td>\n",
       "      <td>8032300.0</td>\n",
       "      <td>6255.149902</td>\n",
       "      <td>6273.310059</td>\n",
       "      <td>6239.220215</td>\n",
       "      <td>6268.560059</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>2025-07-15</td>\n",
       "      <td>110.610001</td>\n",
       "      <td>113.070000</td>\n",
       "      <td>110.209999</td>\n",
       "      <td>112.480003</td>\n",
       "      <td>8105900.0</td>\n",
       "      <td>6295.290039</td>\n",
       "      <td>6302.040039</td>\n",
       "      <td>6241.680176</td>\n",
       "      <td>6243.759766</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>112.400002</td>\n",
       "      <td>120.160004</td>\n",
       "      <td>112.230003</td>\n",
       "      <td>119.019997</td>\n",
       "      <td>15276300.0</td>\n",
       "      <td>6254.500000</td>\n",
       "      <td>6268.120117</td>\n",
       "      <td>6201.589844</td>\n",
       "      <td>6263.700195</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 198 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:52.907405Z",
     "start_time": "2025-07-17T01:41:52.859947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Forward-fill quarterly features (qbs_, qcf_, qis_)\n",
    "quarterly_cols = [col for col in master.columns if any(q in col.lower() for q in ['qbs_', 'qcf_', 'qis_'])]\n",
    "if quarterly_cols:\n",
    "    master[quarterly_cols] = master[quarterly_cols].ffill()\n",
    "\n",
    "master"
   ],
   "id": "49d8fbbcf29370c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date        Open        High         Low       Close      Volume  \\\n",
       "0     2021-03-10   64.500000   74.830002   60.500000   69.500000  97069300.0   \n",
       "1     2021-03-11   74.930000   77.779999   70.129997   73.900002  59629300.0   \n",
       "2     2021-03-12   72.470001   72.959999   69.110001   69.699997  19714700.0   \n",
       "5     2021-03-15   70.019997   74.059998   66.250000   72.150002  19549800.0   \n",
       "6     2021-03-16   73.730003   78.000000   73.180000   77.000000  30274400.0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1591  2025-07-10  106.900002  107.370003  102.730003  105.029999   5636700.0   \n",
       "1592  2025-07-11  104.949997  108.099998  104.809998  105.690002   4544500.0   \n",
       "1595  2025-07-14  106.349998  111.959999  106.349998  111.830002   8032300.0   \n",
       "1596  2025-07-15  110.610001  113.070000  110.209999  112.480003   8105900.0   \n",
       "1597  2025-07-16  112.400002  120.160004  112.230003  119.019997  15276300.0   \n",
       "\n",
       "       SP500_Open   SP500_High    SP500_Low  SP500_Close  ...  \\\n",
       "0     3891.989990  3917.350098  3885.729980  3898.810059  ...   \n",
       "1     3915.540039  3960.270020  3915.540039  3939.340088  ...   \n",
       "2     3924.520020  3944.989990  3915.209961  3943.340088  ...   \n",
       "5     3942.959961  3970.080078  3923.540039  3968.939941  ...   \n",
       "6     3973.590088  3981.040039  3953.439941  3962.709961  ...   \n",
       "...           ...          ...          ...          ...  ...   \n",
       "1591  6266.799805  6290.220215  6251.439941  6280.459961  ...   \n",
       "1592  6255.680176  6269.439941  6237.600098  6259.750000  ...   \n",
       "1595  6255.149902  6273.310059  6239.220215  6268.560059  ...   \n",
       "1596  6295.290039  6302.040039  6241.680176  6243.759766  ...   \n",
       "1597  6254.500000  6268.120117  6201.589844  6263.700195  ...   \n",
       "\n",
       "      qis_Other Operating Expenses  qis_Research And Development  \\\n",
       "0                              NaN                           NaN   \n",
       "1                              NaN                           NaN   \n",
       "2                              NaN                           NaN   \n",
       "5                              NaN                           NaN   \n",
       "6                              NaN                           NaN   \n",
       "...                            ...                           ...   \n",
       "1591                   523691000.0                   374600000.0   \n",
       "1592                   523691000.0                   374600000.0   \n",
       "1595                   523691000.0                   374600000.0   \n",
       "1596                   523691000.0                   374600000.0   \n",
       "1597                   523691000.0                   374600000.0   \n",
       "\n",
       "      qis_Selling General And Administration  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "5                                        NaN   \n",
       "6                                        NaN   \n",
       "...                                      ...   \n",
       "1591                             166900000.0   \n",
       "1592                             166900000.0   \n",
       "1595                             166900000.0   \n",
       "1596                             166900000.0   \n",
       "1597                             166900000.0   \n",
       "\n",
       "      qis_Selling And Marketing Expense  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "5                                   NaN   \n",
       "6                                   NaN   \n",
       "...                                 ...   \n",
       "1591                         47768000.0   \n",
       "1592                         47768000.0   \n",
       "1595                         47768000.0   \n",
       "1596                         47768000.0   \n",
       "1597                         47768000.0   \n",
       "\n",
       "      qis_General And Administrative Expense  qis_Other Gand A  \\\n",
       "0                                        NaN               NaN   \n",
       "1                                        NaN               NaN   \n",
       "2                                        NaN               NaN   \n",
       "5                                        NaN               NaN   \n",
       "6                                        NaN               NaN   \n",
       "...                                      ...               ...   \n",
       "1591                             119132000.0       119132000.0   \n",
       "1592                             119132000.0       119132000.0   \n",
       "1595                             119132000.0       119132000.0   \n",
       "1596                             119132000.0       119132000.0   \n",
       "1597                             119132000.0       119132000.0   \n",
       "\n",
       "      qis_Gross Profit  qis_Cost Of Revenue  qis_Total Revenue  \\\n",
       "0                  NaN                  NaN                NaN   \n",
       "1                  NaN                  NaN                NaN   \n",
       "2                  NaN                  NaN                NaN   \n",
       "5                  NaN                  NaN                NaN   \n",
       "6                  NaN                  NaN                NaN   \n",
       "...                ...                  ...                ...   \n",
       "1591       810482000.0          224725000.0       1.035207e+09   \n",
       "1592       810482000.0          224725000.0       1.035207e+09   \n",
       "1595       810482000.0          224725000.0       1.035207e+09   \n",
       "1596       810482000.0          224725000.0       1.035207e+09   \n",
       "1597       810482000.0          224725000.0       1.035207e+09   \n",
       "\n",
       "      qis_Operating Revenue  \n",
       "0                       NaN  \n",
       "1                       NaN  \n",
       "2                       NaN  \n",
       "5                       NaN  \n",
       "6                       NaN  \n",
       "...                     ...  \n",
       "1591           1.035207e+09  \n",
       "1592           1.035207e+09  \n",
       "1595           1.035207e+09  \n",
       "1596           1.035207e+09  \n",
       "1597           1.035207e+09  \n",
       "\n",
       "[1101 rows x 198 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SP500_Open</th>\n",
       "      <th>SP500_High</th>\n",
       "      <th>SP500_Low</th>\n",
       "      <th>SP500_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>qis_Other Operating Expenses</th>\n",
       "      <th>qis_Research And Development</th>\n",
       "      <th>qis_Selling General And Administration</th>\n",
       "      <th>qis_Selling And Marketing Expense</th>\n",
       "      <th>qis_General And Administrative Expense</th>\n",
       "      <th>qis_Other Gand A</th>\n",
       "      <th>qis_Gross Profit</th>\n",
       "      <th>qis_Cost Of Revenue</th>\n",
       "      <th>qis_Total Revenue</th>\n",
       "      <th>qis_Operating Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>74.830002</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>97069300.0</td>\n",
       "      <td>3891.989990</td>\n",
       "      <td>3917.350098</td>\n",
       "      <td>3885.729980</td>\n",
       "      <td>3898.810059</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>74.930000</td>\n",
       "      <td>77.779999</td>\n",
       "      <td>70.129997</td>\n",
       "      <td>73.900002</td>\n",
       "      <td>59629300.0</td>\n",
       "      <td>3915.540039</td>\n",
       "      <td>3960.270020</td>\n",
       "      <td>3915.540039</td>\n",
       "      <td>3939.340088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-12</td>\n",
       "      <td>72.470001</td>\n",
       "      <td>72.959999</td>\n",
       "      <td>69.110001</td>\n",
       "      <td>69.699997</td>\n",
       "      <td>19714700.0</td>\n",
       "      <td>3924.520020</td>\n",
       "      <td>3944.989990</td>\n",
       "      <td>3915.209961</td>\n",
       "      <td>3943.340088</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>70.019997</td>\n",
       "      <td>74.059998</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>72.150002</td>\n",
       "      <td>19549800.0</td>\n",
       "      <td>3942.959961</td>\n",
       "      <td>3970.080078</td>\n",
       "      <td>3923.540039</td>\n",
       "      <td>3968.939941</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-16</td>\n",
       "      <td>73.730003</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>73.180000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>30274400.0</td>\n",
       "      <td>3973.590088</td>\n",
       "      <td>3981.040039</td>\n",
       "      <td>3953.439941</td>\n",
       "      <td>3962.709961</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>2025-07-10</td>\n",
       "      <td>106.900002</td>\n",
       "      <td>107.370003</td>\n",
       "      <td>102.730003</td>\n",
       "      <td>105.029999</td>\n",
       "      <td>5636700.0</td>\n",
       "      <td>6266.799805</td>\n",
       "      <td>6290.220215</td>\n",
       "      <td>6251.439941</td>\n",
       "      <td>6280.459961</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>2025-07-11</td>\n",
       "      <td>104.949997</td>\n",
       "      <td>108.099998</td>\n",
       "      <td>104.809998</td>\n",
       "      <td>105.690002</td>\n",
       "      <td>4544500.0</td>\n",
       "      <td>6255.680176</td>\n",
       "      <td>6269.439941</td>\n",
       "      <td>6237.600098</td>\n",
       "      <td>6259.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>2025-07-14</td>\n",
       "      <td>106.349998</td>\n",
       "      <td>111.959999</td>\n",
       "      <td>106.349998</td>\n",
       "      <td>111.830002</td>\n",
       "      <td>8032300.0</td>\n",
       "      <td>6255.149902</td>\n",
       "      <td>6273.310059</td>\n",
       "      <td>6239.220215</td>\n",
       "      <td>6268.560059</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>2025-07-15</td>\n",
       "      <td>110.610001</td>\n",
       "      <td>113.070000</td>\n",
       "      <td>110.209999</td>\n",
       "      <td>112.480003</td>\n",
       "      <td>8105900.0</td>\n",
       "      <td>6295.290039</td>\n",
       "      <td>6302.040039</td>\n",
       "      <td>6241.680176</td>\n",
       "      <td>6243.759766</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>2025-07-16</td>\n",
       "      <td>112.400002</td>\n",
       "      <td>120.160004</td>\n",
       "      <td>112.230003</td>\n",
       "      <td>119.019997</td>\n",
       "      <td>15276300.0</td>\n",
       "      <td>6254.500000</td>\n",
       "      <td>6268.120117</td>\n",
       "      <td>6201.589844</td>\n",
       "      <td>6263.700195</td>\n",
       "      <td>...</td>\n",
       "      <td>523691000.0</td>\n",
       "      <td>374600000.0</td>\n",
       "      <td>166900000.0</td>\n",
       "      <td>47768000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>119132000.0</td>\n",
       "      <td>810482000.0</td>\n",
       "      <td>224725000.0</td>\n",
       "      <td>1.035207e+09</td>\n",
       "      <td>1.035207e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1101 rows × 198 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:53.036054Z",
     "start_time": "2025-07-17T01:41:53.023543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Forward-fill/interpolate daily user/engagement features\n",
    "daily_fill_cols = [\n",
    "    'registrations', 'ccu', 'session_length', 'popular_games_total'\n",
    "]\n",
    "daily_fill_cols = [col for col in daily_fill_cols if col in master.columns]\n",
    "if daily_fill_cols:\n",
    "    master[daily_fill_cols] = master[daily_fill_cols].interpolate(method='linear', limit_direction='both')\n",
    "    master[daily_fill_cols] = master[daily_fill_cols].ffill().bfill()"
   ],
   "id": "b2beee21fb74d775",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:53.133386Z",
     "start_time": "2025-07-17T01:41:53.117627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "master['date'] = pd.to_datetime(master['date'], errors='coerce')\n",
    "# Drop duplicate dates\n",
    "master = master.drop_duplicates(subset=['date'], keep='first')\n",
    "master = master.sort_values('date').reset_index(drop=True)\n",
    "master = master.drop(columns=['fog_index', 'filename', 'form_type'])"
   ],
   "id": "3f174b1cc4977be9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:53.684264Z",
     "start_time": "2025-07-17T01:41:53.445782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_numeric(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    val = str(val).replace('<null>', '').replace('None', '').replace('', '')\n",
    "    # Replace Unicode dashes with ASCII minus\n",
    "    val = val.replace('\\u2013', '-')  # EN DASH\n",
    "    val = val.replace('\\u2014', '-')  # EM DASH\n",
    "    val = val.replace('\\u2212', '-')  # MINUS SIGN\n",
    "    val = val.replace(',', '')        # Remove commas (thousands separators)\n",
    "    val = val.replace('(', '-')       # Handle accounting negatives\n",
    "    val = val.replace(')', '')\n",
    "    val = val.strip()\n",
    "    if val == '':\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(val)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Replace all null-like values globally with np.nan\n",
    "master = master.replace({'<null>': np.nan, 'nan': np.nan, 'None': np.nan, '': np.nan})\n",
    "\n",
    "# Clean ALL columns except 'date'\n",
    "for col in master.columns:\n",
    "    if col.lower() == 'date':\n",
    "        continue\n",
    "    master[col] = master[col].apply(clean_numeric)"
   ],
   "id": "8209fbb21f75ca76",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:53.974064Z",
     "start_time": "2025-07-17T01:41:53.827068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 7. Save the cleaned dataset\n",
    "master.to_csv(\"../data/master_dataset_cleaned.csv\", index=False)\n",
    "print(\"Cleaned master dataset saved as master_dataset_cleaned.csv\")"
   ],
   "id": "e05472ad3f289f90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned master dataset saved as master_dataset_cleaned.csv\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:41:54.203463Z",
     "start_time": "2025-07-17T01:41:54.168115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8. Check quarterly feature filling worked (print first 40 non-NaN rows)\n",
    "if quarterly_cols:\n",
    "    quarterly_data = master[['date'] + quarterly_cols]\n",
    "    print(\"\\nFirst rows with quarterly features filled:\")\n",
    "    print(quarterly_data[quarterly_data[quarterly_cols[0]].notna()].head(40))"
   ],
   "id": "9d1e4f8691ea445f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First rows with quarterly features filled:\n",
      "         date  qbs_Ordinary Shares Number  qbs_Share Issued  qbs_Net Debt  \\\n",
      "15 2021-03-31                 568894000.0       568894000.0  1.600000e+09   \n",
      "16 2021-04-01                 568894000.0       568894000.0  1.600000e+09   \n",
      "17 2021-04-05                 568894000.0       568894000.0  1.600000e+09   \n",
      "18 2021-04-06                 568894000.0       568894000.0  1.600000e+09   \n",
      "19 2021-04-07                 568894000.0       568894000.0  1.600000e+09   \n",
      "20 2021-04-08                 568894000.0       568894000.0  1.600000e+09   \n",
      "21 2021-04-09                 568894000.0       568894000.0  1.600000e+09   \n",
      "22 2021-04-12                 568894000.0       568894000.0  1.600000e+09   \n",
      "23 2021-04-13                 568894000.0       568894000.0  1.600000e+09   \n",
      "24 2021-04-14                 568894000.0       568894000.0  1.600000e+09   \n",
      "25 2021-04-15                 568894000.0       568894000.0  1.600000e+09   \n",
      "26 2021-04-16                 568894000.0       568894000.0  1.600000e+09   \n",
      "27 2021-04-19                 568894000.0       568894000.0  1.600000e+09   \n",
      "28 2021-04-20                 568894000.0       568894000.0  1.600000e+09   \n",
      "29 2021-04-21                 568894000.0       568894000.0  1.600000e+09   \n",
      "30 2021-04-22                 568894000.0       568894000.0  1.600000e+09   \n",
      "31 2021-04-23                 568894000.0       568894000.0  1.600000e+09   \n",
      "32 2021-04-26                 568894000.0       568894000.0  1.600000e+09   \n",
      "33 2021-04-27                 568894000.0       568894000.0  1.600000e+09   \n",
      "34 2021-04-28                 568894000.0       568894000.0  1.600000e+09   \n",
      "35 2021-04-29                 568894000.0       568894000.0  1.600000e+09   \n",
      "36 2021-04-30                 568894000.0       568894000.0  1.600000e+09   \n",
      "37 2021-05-03                 568894000.0       568894000.0  1.600000e+09   \n",
      "38 2021-05-04                 568894000.0       568894000.0  1.600000e+09   \n",
      "39 2021-05-05                 568894000.0       568894000.0  1.600000e+09   \n",
      "40 2021-05-06                 568894000.0       568894000.0  1.600000e+09   \n",
      "41 2021-05-07                 568894000.0       568894000.0  1.600000e+09   \n",
      "42 2021-05-10                 568894000.0       568894000.0  1.600000e+09   \n",
      "43 2021-05-11                 568894000.0       568894000.0  1.600000e+09   \n",
      "44 2021-05-12                 568894000.0       568894000.0  1.600000e+09   \n",
      "45 2021-05-13                 568894000.0       568894000.0  1.600000e+09   \n",
      "46 2021-05-14                 568894000.0       568894000.0  1.600000e+09   \n",
      "47 2021-05-17                 568894000.0       568894000.0  1.600000e+09   \n",
      "48 2021-05-18                 568894000.0       568894000.0  1.600000e+09   \n",
      "49 2021-05-19                 568894000.0       568894000.0  1.600000e+09   \n",
      "50 2021-05-20                 568894000.0       568894000.0  1.600000e+09   \n",
      "51 2021-05-21                 568894000.0       568894000.0  1.600000e+09   \n",
      "52 2021-05-24                 568894000.0       568894000.0  1.600000e+09   \n",
      "53 2021-05-25                 568894000.0       568894000.0  1.600000e+09   \n",
      "54 2021-05-26                 568894000.0       568894000.0  1.600000e+09   \n",
      "\n",
      "    qbs_Total Debt  qbs_Tangible Book Value  qbs_Invested Capital  \\\n",
      "15     988984000.0              424000000.0          1.412984e+09   \n",
      "16     988984000.0              424000000.0          1.412984e+09   \n",
      "17     988984000.0              424000000.0          1.412984e+09   \n",
      "18     988984000.0              424000000.0          1.412984e+09   \n",
      "19     988984000.0              424000000.0          1.412984e+09   \n",
      "20     988984000.0              424000000.0          1.412984e+09   \n",
      "21     988984000.0              424000000.0          1.412984e+09   \n",
      "22     988984000.0              424000000.0          1.412984e+09   \n",
      "23     988984000.0              424000000.0          1.412984e+09   \n",
      "24     988984000.0              424000000.0          1.412984e+09   \n",
      "25     988984000.0              424000000.0          1.412984e+09   \n",
      "26     988984000.0              424000000.0          1.412984e+09   \n",
      "27     988984000.0              424000000.0          1.412984e+09   \n",
      "28     988984000.0              424000000.0          1.412984e+09   \n",
      "29     988984000.0              424000000.0          1.412984e+09   \n",
      "30     988984000.0              424000000.0          1.412984e+09   \n",
      "31     988984000.0              424000000.0          1.412984e+09   \n",
      "32     988984000.0              424000000.0          1.412984e+09   \n",
      "33     988984000.0              424000000.0          1.412984e+09   \n",
      "34     988984000.0              424000000.0          1.412984e+09   \n",
      "35     988984000.0              424000000.0          1.412984e+09   \n",
      "36     988984000.0              424000000.0          1.412984e+09   \n",
      "37     988984000.0              424000000.0          1.412984e+09   \n",
      "38     988984000.0              424000000.0          1.412984e+09   \n",
      "39     988984000.0              424000000.0          1.412984e+09   \n",
      "40     988984000.0              424000000.0          1.412984e+09   \n",
      "41     988984000.0              424000000.0          1.412984e+09   \n",
      "42     988984000.0              424000000.0          1.412984e+09   \n",
      "43     988984000.0              424000000.0          1.412984e+09   \n",
      "44     988984000.0              424000000.0          1.412984e+09   \n",
      "45     988984000.0              424000000.0          1.412984e+09   \n",
      "46     988984000.0              424000000.0          1.412984e+09   \n",
      "47     988984000.0              424000000.0          1.412984e+09   \n",
      "48     988984000.0              424000000.0          1.412984e+09   \n",
      "49     988984000.0              424000000.0          1.412984e+09   \n",
      "50     988984000.0              424000000.0          1.412984e+09   \n",
      "51     988984000.0              424000000.0          1.412984e+09   \n",
      "52     988984000.0              424000000.0          1.412984e+09   \n",
      "53     988984000.0              424000000.0          1.412984e+09   \n",
      "54     988984000.0              424000000.0          1.412984e+09   \n",
      "\n",
      "    qbs_Working Capital  qbs_Net Tangible Assets  \\\n",
      "15          662479000.0             2.540309e+09   \n",
      "16          662479000.0             2.540309e+09   \n",
      "17          662479000.0             2.540309e+09   \n",
      "18          662479000.0             2.540309e+09   \n",
      "19          662479000.0             2.540309e+09   \n",
      "20          662479000.0             2.540309e+09   \n",
      "21          662479000.0             2.540309e+09   \n",
      "22          662479000.0             2.540309e+09   \n",
      "23          662479000.0             2.540309e+09   \n",
      "24          662479000.0             2.540309e+09   \n",
      "25          662479000.0             2.540309e+09   \n",
      "26          662479000.0             2.540309e+09   \n",
      "27          662479000.0             2.540309e+09   \n",
      "28          662479000.0             2.540309e+09   \n",
      "29          662479000.0             2.540309e+09   \n",
      "30          662479000.0             2.540309e+09   \n",
      "31          662479000.0             2.540309e+09   \n",
      "32          662479000.0             2.540309e+09   \n",
      "33          662479000.0             2.540309e+09   \n",
      "34          662479000.0             2.540309e+09   \n",
      "35          662479000.0             2.540309e+09   \n",
      "36          662479000.0             2.540309e+09   \n",
      "37          662479000.0             2.540309e+09   \n",
      "38          662479000.0             2.540309e+09   \n",
      "39          662479000.0             2.540309e+09   \n",
      "40          662479000.0             2.540309e+09   \n",
      "41          662479000.0             2.540309e+09   \n",
      "42          662479000.0             2.540309e+09   \n",
      "43          662479000.0             2.540309e+09   \n",
      "44          662479000.0             2.540309e+09   \n",
      "45          662479000.0             2.540309e+09   \n",
      "46          662479000.0             2.540309e+09   \n",
      "47          662479000.0             2.540309e+09   \n",
      "48          662479000.0             2.540309e+09   \n",
      "49          662479000.0             2.540309e+09   \n",
      "50          662479000.0             2.540309e+09   \n",
      "51          662479000.0             2.540309e+09   \n",
      "52          662479000.0             2.540309e+09   \n",
      "53          662479000.0             2.540309e+09   \n",
      "54          662479000.0             2.540309e+09   \n",
      "\n",
      "    qbs_Capital Lease Obligations  ...  qis_Other Operating Expenses  \\\n",
      "15                    205117000.0  ...                   163600000.0   \n",
      "16                    205117000.0  ...                   163600000.0   \n",
      "17                    205117000.0  ...                   163600000.0   \n",
      "18                    205117000.0  ...                   163600000.0   \n",
      "19                    205117000.0  ...                   163600000.0   \n",
      "20                    205117000.0  ...                   163600000.0   \n",
      "21                    205117000.0  ...                   163600000.0   \n",
      "22                    205117000.0  ...                   163600000.0   \n",
      "23                    205117000.0  ...                   163600000.0   \n",
      "24                    205117000.0  ...                   163600000.0   \n",
      "25                    205117000.0  ...                   163600000.0   \n",
      "26                    205117000.0  ...                   163600000.0   \n",
      "27                    205117000.0  ...                   163600000.0   \n",
      "28                    205117000.0  ...                   163600000.0   \n",
      "29                    205117000.0  ...                   163600000.0   \n",
      "30                    205117000.0  ...                   163600000.0   \n",
      "31                    205117000.0  ...                   163600000.0   \n",
      "32                    205117000.0  ...                   163600000.0   \n",
      "33                    205117000.0  ...                   163600000.0   \n",
      "34                    205117000.0  ...                   163600000.0   \n",
      "35                    205117000.0  ...                   163600000.0   \n",
      "36                    205117000.0  ...                   163600000.0   \n",
      "37                    205117000.0  ...                   163600000.0   \n",
      "38                    205117000.0  ...                   163600000.0   \n",
      "39                    205117000.0  ...                   163600000.0   \n",
      "40                    205117000.0  ...                   163600000.0   \n",
      "41                    205117000.0  ...                   163600000.0   \n",
      "42                    205117000.0  ...                   163600000.0   \n",
      "43                    205117000.0  ...                   163600000.0   \n",
      "44                    205117000.0  ...                   163600000.0   \n",
      "45                    205117000.0  ...                   163600000.0   \n",
      "46                    205117000.0  ...                   163600000.0   \n",
      "47                    205117000.0  ...                   163600000.0   \n",
      "48                    205117000.0  ...                   163600000.0   \n",
      "49                    205117000.0  ...                   163600000.0   \n",
      "50                    205117000.0  ...                   163600000.0   \n",
      "51                    205117000.0  ...                   163600000.0   \n",
      "52                    205117000.0  ...                   163600000.0   \n",
      "53                    205117000.0  ...                   163600000.0   \n",
      "54                    205117000.0  ...                   163600000.0   \n",
      "\n",
      "    qis_Research And Development  qis_Selling General And Administration  \\\n",
      "15                    89700000.0                              73900000.0   \n",
      "16                    89700000.0                              73900000.0   \n",
      "17                    89700000.0                              73900000.0   \n",
      "18                    89700000.0                              73900000.0   \n",
      "19                    89700000.0                              73900000.0   \n",
      "20                    89700000.0                              73900000.0   \n",
      "21                    89700000.0                              73900000.0   \n",
      "22                    89700000.0                              73900000.0   \n",
      "23                    89700000.0                              73900000.0   \n",
      "24                    89700000.0                              73900000.0   \n",
      "25                    89700000.0                              73900000.0   \n",
      "26                    89700000.0                              73900000.0   \n",
      "27                    89700000.0                              73900000.0   \n",
      "28                    89700000.0                              73900000.0   \n",
      "29                    89700000.0                              73900000.0   \n",
      "30                    89700000.0                              73900000.0   \n",
      "31                    89700000.0                              73900000.0   \n",
      "32                    89700000.0                              73900000.0   \n",
      "33                    89700000.0                              73900000.0   \n",
      "34                    89700000.0                              73900000.0   \n",
      "35                    89700000.0                              73900000.0   \n",
      "36                    89700000.0                              73900000.0   \n",
      "37                    89700000.0                              73900000.0   \n",
      "38                    89700000.0                              73900000.0   \n",
      "39                    89700000.0                              73900000.0   \n",
      "40                    89700000.0                              73900000.0   \n",
      "41                    89700000.0                              73900000.0   \n",
      "42                    89700000.0                              73900000.0   \n",
      "43                    89700000.0                              73900000.0   \n",
      "44                    89700000.0                              73900000.0   \n",
      "45                    89700000.0                              73900000.0   \n",
      "46                    89700000.0                              73900000.0   \n",
      "47                    89700000.0                              73900000.0   \n",
      "48                    89700000.0                              73900000.0   \n",
      "49                    89700000.0                              73900000.0   \n",
      "50                    89700000.0                              73900000.0   \n",
      "51                    89700000.0                              73900000.0   \n",
      "52                    89700000.0                              73900000.0   \n",
      "53                    89700000.0                              73900000.0   \n",
      "54                    89700000.0                              73900000.0   \n",
      "\n",
      "    qis_Selling And Marketing Expense  qis_General And Administrative Expense  \\\n",
      "15                         11500000.0                              62400000.0   \n",
      "16                         11500000.0                              62400000.0   \n",
      "17                         11500000.0                              62400000.0   \n",
      "18                         11500000.0                              62400000.0   \n",
      "19                         11500000.0                              62400000.0   \n",
      "20                         11500000.0                              62400000.0   \n",
      "21                         11500000.0                              62400000.0   \n",
      "22                         11500000.0                              62400000.0   \n",
      "23                         11500000.0                              62400000.0   \n",
      "24                         11500000.0                              62400000.0   \n",
      "25                         11500000.0                              62400000.0   \n",
      "26                         11500000.0                              62400000.0   \n",
      "27                         11500000.0                              62400000.0   \n",
      "28                         11500000.0                              62400000.0   \n",
      "29                         11500000.0                              62400000.0   \n",
      "30                         11500000.0                              62400000.0   \n",
      "31                         11500000.0                              62400000.0   \n",
      "32                         11500000.0                              62400000.0   \n",
      "33                         11500000.0                              62400000.0   \n",
      "34                         11500000.0                              62400000.0   \n",
      "35                         11500000.0                              62400000.0   \n",
      "36                         11500000.0                              62400000.0   \n",
      "37                         11500000.0                              62400000.0   \n",
      "38                         11500000.0                              62400000.0   \n",
      "39                         11500000.0                              62400000.0   \n",
      "40                         11500000.0                              62400000.0   \n",
      "41                         11500000.0                              62400000.0   \n",
      "42                         11500000.0                              62400000.0   \n",
      "43                         11500000.0                              62400000.0   \n",
      "44                         11500000.0                              62400000.0   \n",
      "45                         11500000.0                              62400000.0   \n",
      "46                         11500000.0                              62400000.0   \n",
      "47                         11500000.0                              62400000.0   \n",
      "48                         11500000.0                              62400000.0   \n",
      "49                         11500000.0                              62400000.0   \n",
      "50                         11500000.0                              62400000.0   \n",
      "51                         11500000.0                              62400000.0   \n",
      "52                         11500000.0                              62400000.0   \n",
      "53                         11500000.0                              62400000.0   \n",
      "54                         11500000.0                              62400000.0   \n",
      "\n",
      "    qis_Other Gand A  qis_Gross Profit  qis_Cost Of Revenue  \\\n",
      "15        62400000.0       307400000.0           79700000.0   \n",
      "16        62400000.0       307400000.0           79700000.0   \n",
      "17        62400000.0       307400000.0           79700000.0   \n",
      "18        62400000.0       307400000.0           79700000.0   \n",
      "19        62400000.0       307400000.0           79700000.0   \n",
      "20        62400000.0       307400000.0           79700000.0   \n",
      "21        62400000.0       307400000.0           79700000.0   \n",
      "22        62400000.0       307400000.0           79700000.0   \n",
      "23        62400000.0       307400000.0           79700000.0   \n",
      "24        62400000.0       307400000.0           79700000.0   \n",
      "25        62400000.0       307400000.0           79700000.0   \n",
      "26        62400000.0       307400000.0           79700000.0   \n",
      "27        62400000.0       307400000.0           79700000.0   \n",
      "28        62400000.0       307400000.0           79700000.0   \n",
      "29        62400000.0       307400000.0           79700000.0   \n",
      "30        62400000.0       307400000.0           79700000.0   \n",
      "31        62400000.0       307400000.0           79700000.0   \n",
      "32        62400000.0       307400000.0           79700000.0   \n",
      "33        62400000.0       307400000.0           79700000.0   \n",
      "34        62400000.0       307400000.0           79700000.0   \n",
      "35        62400000.0       307400000.0           79700000.0   \n",
      "36        62400000.0       307400000.0           79700000.0   \n",
      "37        62400000.0       307400000.0           79700000.0   \n",
      "38        62400000.0       307400000.0           79700000.0   \n",
      "39        62400000.0       307400000.0           79700000.0   \n",
      "40        62400000.0       307400000.0           79700000.0   \n",
      "41        62400000.0       307400000.0           79700000.0   \n",
      "42        62400000.0       307400000.0           79700000.0   \n",
      "43        62400000.0       307400000.0           79700000.0   \n",
      "44        62400000.0       307400000.0           79700000.0   \n",
      "45        62400000.0       307400000.0           79700000.0   \n",
      "46        62400000.0       307400000.0           79700000.0   \n",
      "47        62400000.0       307400000.0           79700000.0   \n",
      "48        62400000.0       307400000.0           79700000.0   \n",
      "49        62400000.0       307400000.0           79700000.0   \n",
      "50        62400000.0       307400000.0           79700000.0   \n",
      "51        62400000.0       307400000.0           79700000.0   \n",
      "52        62400000.0       307400000.0           79700000.0   \n",
      "53        62400000.0       307400000.0           79700000.0   \n",
      "54        62400000.0       307400000.0           79700000.0   \n",
      "\n",
      "    qis_Total Revenue  qis_Operating Revenue  \n",
      "15        387000000.0            387000000.0  \n",
      "16        387000000.0            387000000.0  \n",
      "17        387000000.0            387000000.0  \n",
      "18        387000000.0            387000000.0  \n",
      "19        387000000.0            387000000.0  \n",
      "20        387000000.0            387000000.0  \n",
      "21        387000000.0            387000000.0  \n",
      "22        387000000.0            387000000.0  \n",
      "23        387000000.0            387000000.0  \n",
      "24        387000000.0            387000000.0  \n",
      "25        387000000.0            387000000.0  \n",
      "26        387000000.0            387000000.0  \n",
      "27        387000000.0            387000000.0  \n",
      "28        387000000.0            387000000.0  \n",
      "29        387000000.0            387000000.0  \n",
      "30        387000000.0            387000000.0  \n",
      "31        387000000.0            387000000.0  \n",
      "32        387000000.0            387000000.0  \n",
      "33        387000000.0            387000000.0  \n",
      "34        387000000.0            387000000.0  \n",
      "35        387000000.0            387000000.0  \n",
      "36        387000000.0            387000000.0  \n",
      "37        387000000.0            387000000.0  \n",
      "38        387000000.0            387000000.0  \n",
      "39        387000000.0            387000000.0  \n",
      "40        387000000.0            387000000.0  \n",
      "41        387000000.0            387000000.0  \n",
      "42        387000000.0            387000000.0  \n",
      "43        387000000.0            387000000.0  \n",
      "44        387000000.0            387000000.0  \n",
      "45        387000000.0            387000000.0  \n",
      "46        387000000.0            387000000.0  \n",
      "47        387000000.0            387000000.0  \n",
      "48        387000000.0            387000000.0  \n",
      "49        387000000.0            387000000.0  \n",
      "50        387000000.0            387000000.0  \n",
      "51        387000000.0            387000000.0  \n",
      "52        387000000.0            387000000.0  \n",
      "53        387000000.0            387000000.0  \n",
      "54        387000000.0            387000000.0  \n",
      "\n",
      "[40 rows x 165 columns]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T01:42:12.653844Z",
     "start_time": "2025-07-17T01:41:54.371648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "# 1. Load & sort your data\n",
    "df = pd.read_csv('../data/master_dataset_cleaned.csv', parse_dates=['date'])\n",
    "df.sort_values('date', inplace=True)\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# 2. Specify the sentiment columns and bootstrap-missing with column means\n",
    "sent_cols = ['neg', 'neu', 'pos', 'compound']\n",
    "col_means = df[sent_cols].mean()\n",
    "df_init = df[sent_cols].fillna(col_means)\n",
    "\n",
    "# 3. Scale into [0,1] for the LSTM\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df_init)\n",
    "\n",
    "# 4. Build sequences (look_back days → predict next day)\n",
    "def create_sequences(arr, look_back=7):\n",
    "    X, y = [], []\n",
    "    for i in range(look_back, len(arr)):\n",
    "        X.append(arr[i-look_back:i])\n",
    "        y.append(arr[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "look_back = 7\n",
    "X, y = create_sequences(data_scaled, look_back)\n",
    "\n",
    "# 5. Train/test split\n",
    "dataset = TensorDataset(torch.tensor(X, dtype=torch.float32),\n",
    "                        torch.tensor(y, dtype=torch.float32))\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "train_ds, test_ds = random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=16)\n",
    "\n",
    "# 6. Define your LSTM imputer\n",
    "class ImputerLSTM(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_features, hidden_size, batch_first=True)\n",
    "        self.out  = nn.Linear(hidden_size, n_features)\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, features]\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return self.out(h_n[-1])  # use last layer's final hidden\n",
    "\n",
    "model = ImputerLSTM(n_features=len(sent_cols), hidden_size=32)\n",
    "\n",
    "# 7. Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "best_val = float('inf')\n",
    "patience = 5\n",
    "wait = 0\n",
    "best_state = None\n",
    "\n",
    "# 8. Train with early stopping\n",
    "for epoch in range(1, 51):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = [criterion(model(xb), yb).item()\n",
    "                      for xb, yb in test_loader]\n",
    "    val_loss = np.mean(val_losses)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        best_state = model.state_dict()\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(f\"Stopping early at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "# restore best\n",
    "model.load_state_dict(best_state)\n",
    "model.eval()\n",
    "\n",
    "# 9. Impute missing rows\n",
    "missing_dates = df[df[sent_cols].isnull().any(axis=1)].index\n",
    "all_scaled = torch.tensor(data_scaled, dtype=torch.float32)\n",
    "\n",
    "for dt in missing_dates:\n",
    "    idx = df.index.get_loc(dt)\n",
    "    if idx >= look_back:\n",
    "        seq = all_scaled[idx-look_back:idx].unsqueeze(0)  # [1, look_back, features]\n",
    "        with torch.no_grad():\n",
    "            pred_scaled = model(seq).numpy()\n",
    "        df.loc[dt, sent_cols] = scaler.inverse_transform(pred_scaled)[0]\n",
    "\n",
    "# 10. Check results\n",
    "print(\"Remaining NaNs per column:\\n\", df[sent_cols].isna().sum())\n",
    "print(\"\\nFirst few imputed rows:\")\n",
    "print(df.loc[missing_dates[:5], sent_cols])\n",
    "\n",
    "df.to_csv('../data/master_dataset_cleaned.csv', index=True)\n",
    "\n"
   ],
   "id": "84a2529934e30ee5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early at epoch 34\n",
      "Remaining NaNs per column:\n",
      " neg         0\n",
      "neu         0\n",
      "pos         0\n",
      "compound    0\n",
      "dtype: int64\n",
      "\n",
      "First few imputed rows:\n",
      "                 neg       neu       pos  compound\n",
      "date                                              \n",
      "2021-03-23  0.045944  0.861251  0.087522  0.136717\n",
      "2021-03-24  0.046739  0.857825  0.089266  0.127215\n",
      "2021-03-26  0.064049  0.843266  0.085045  0.058122\n",
      "2021-03-31  0.077096  0.833341  0.083796  0.009647\n",
      "2021-04-01  0.067255  0.834247  0.091124  0.032901\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
