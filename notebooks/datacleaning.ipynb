{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-25T04:12:20.066699Z",
     "start_time": "2025-06-25T04:12:19.810187Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "\n",
    "from bs4.diagnose import lxml_trace\n",
    "\n",
    "DATA_DIR = \"../data/romonitor_data/\"\n",
    "OUTPUT_DIR = \"../data/romonitor_data_clean/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_timeseries_from_data(file, value_colname):\n",
    "    df = pd.read_csv(DATA_DIR + file)\n",
    "    # Only keep rows with a real 'name' (not metadata)\n",
    "    df = df[df['name'].notna()]\n",
    "    # Parse the dict in 'data'\n",
    "    data_dict = ast.literal_eval(df.iloc[0]['data'])\n",
    "    # Convert to DataFrame\n",
    "    ts_df = pd.DataFrame(list(data_dict.items()), columns=['date', value_colname])\n",
    "    ts_df['date'] = pd.to_datetime(ts_df['date']).dt.strftime('%Y-%m-%d')\n",
    "    ts_df = ts_df.sort_values('date').reset_index(drop=True)\n",
    "    ts_df.to_csv(OUTPUT_DIR + value_colname + '.csv', index=False)\n",
    "    print(f\"Saved: {OUTPUT_DIR}{value_colname}.csv\")\n",
    "    return ts_df\n",
    "\n",
    "def extract_and_sum_popular_games():\n",
    "    df = pd.read_csv(DATA_DIR + 'popular_games.csv')\n",
    "    df = df[df['name'].notna()]\n",
    "    game_dfs = []\n",
    "    for _, row in df.iterrows():\n",
    "        data_raw = row['data']\n",
    "        try:\n",
    "            data_dict = ast.literal_eval(data_raw)\n",
    "        except:\n",
    "            continue  \n",
    "        if isinstance(data_dict, dict):\n",
    "            game_df = pd.DataFrame(list(data_dict.items()), columns=['date', 'value'])\n",
    "            game_df['date'] = pd.to_datetime(game_df['date'])\n",
    "            game_dfs.append(game_df)\n",
    "    if not game_dfs:\n",
    "        print(\"No games with usable data found!\")\n",
    "        return None\n",
    "    all_games = pd.concat(game_dfs)\n",
    "    sum_games = all_games.groupby(all_games['date'].dt.strftime('%Y-%m-%d'))['value'].sum().reset_index()\n",
    "    sum_games = sum_games.rename(columns={'value': 'popular_games_total'})\n",
    "    sum_games.to_csv(OUTPUT_DIR + 'popular_games_total.csv', index=False)\n",
    "    print(f\"Saved: {OUTPUT_DIR}popular_games_total.csv\")\n",
    "    return sum_games\n",
    "\n",
    "# Clean and save time series\n",
    "extract_timeseries_from_data('ccu.csv', 'ccu')\n",
    "extract_timeseries_from_data('registrations.csv', 'registrations')\n",
    "extract_timeseries_from_data('session_length.csv', 'session_length')\n",
    "extract_and_sum_popular_games()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../data/romonitor_data_clean/ccu.csv\n",
      "Saved: ../data/romonitor_data_clean/registrations.csv\n",
      "Saved: ../data/romonitor_data_clean/session_length.csv\n",
      "Saved: ../data/romonitor_data_clean/popular_games_total.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "          date  popular_games_total\n",
       "0   2025-05-06           79758549.0\n",
       "1   2025-05-07           79997871.0\n",
       "2   2025-05-08           81165810.0\n",
       "3   2025-05-09           89288600.0\n",
       "4   2025-05-10          116785967.0\n",
       "5   2025-05-11          114392357.0\n",
       "6   2025-05-12           79589010.0\n",
       "7   2025-05-13           75347467.0\n",
       "8   2025-05-14           75645524.0\n",
       "9   2025-05-15           75085390.0\n",
       "10  2025-05-16           77687171.0\n",
       "11  2025-05-17          108026313.0\n",
       "12  2025-05-18          108439485.0\n",
       "13  2025-05-19           75299253.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>popular_games_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>79758549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>79997871.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-08</td>\n",
       "      <td>81165810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-09</td>\n",
       "      <td>89288600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-10</td>\n",
       "      <td>116785967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-05-11</td>\n",
       "      <td>114392357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-05-12</td>\n",
       "      <td>79589010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-05-13</td>\n",
       "      <td>75347467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-05-14</td>\n",
       "      <td>75645524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>75085390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>77687171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2025-05-17</td>\n",
       "      <td>108026313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2025-05-18</td>\n",
       "      <td>108439485.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>75299253.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T04:12:20.116635Z",
     "start_time": "2025-06-25T04:12:20.074961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_quarterly_fundamental(filepath, prefix=None):\n",
    "    # Load and transpose so dates are rows, metrics are columns\n",
    "    df = pd.read_csv(filepath, index_col=0).transpose()\n",
    "\n",
    "    df = df.reset_index().rename(columns={'index': 'date'})\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "    if prefix:\n",
    "        newcols = ['date'] + [f\"{prefix}{col}\" for col in df.columns if col != 'date']\n",
    "        df.columns = newcols\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# EXAMPLES:\n",
    "# Cleaned income statement\n",
    "qis = clean_quarterly_fundamental(\"../data/RBLX_quarterly_income_statement.csv\", prefix=\"qis_\")\n",
    "qis.to_csv(\"../data/cleaned_quarterly_income_statement.csv\", index=False)\n",
    "\n",
    "# Cleaned balance sheet\n",
    "qbs = clean_quarterly_fundamental(\"../data/RBLX_quarterly_balance_sheet.csv\", prefix=\"qbs_\")\n",
    "qbs.to_csv(\"../data/cleaned_quarterly_balance_sheet.csv\", index=False)\n",
    "\n",
    "# Cleaned cash flow\n",
    "qcf = clean_quarterly_fundamental(\"../data/RBLX_quarterly_cashflow.csv\", prefix=\"qcf_\")\n",
    "qcf.to_csv(\"../data/cleaned_quarterly_cashflow.csv\", index=False)"
   ],
   "id": "236bf0e5e0915b3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T04:12:20.136419Z",
     "start_time": "2025-06-25T04:12:20.134086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parsing and extracting SEC file data \n",
    "\n",
    "# Refer to sec_file_cleaning.py"
   ],
   "id": "196610134c543129",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T04:12:20.441092Z",
     "start_time": "2025-06-25T04:12:20.144199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Merge All the data together\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_date_column(df):\n",
    "    # Rename any column with 'date' (case-insensitive) to 'date'\n",
    "    for col in df.columns:\n",
    "        if col.lower() == 'date':\n",
    "            df = df.rename(columns={col: 'date'})\n",
    "            break\n",
    "    return df\n",
    "\n",
    "def move_to_monday(date):\n",
    "    if date.weekday() == 5:  # Saturday\n",
    "        return date + pd.Timedelta(days=2)\n",
    "    elif date.weekday() == 6:  # Sunday\n",
    "        return date + pd.Timedelta(days=1)\n",
    "    else:\n",
    "        return date\n",
    "\n",
    "# --- Load Data ---\n",
    "stock = pd.read_csv(\"../data/RBLX_with_technicals.csv\")\n",
    "sp500 = pd.read_csv(\"../data/SP500.csv\")\n",
    "nasdaq = pd.read_csv(\"../data/Nasdaq.csv\")\n",
    "popular_games_total = pd.read_csv(\"../data/romonitor_data_clean/popular_games_total.csv\")\n",
    "registrations = pd.read_csv(\"../data/romonitor_data_clean/registrations.csv\")\n",
    "ccu = pd.read_csv(\"../data/romonitor_data_clean/ccu.csv\")\n",
    "session_length = pd.read_csv(\"../data/romonitor_data_clean/session_length.csv\")\n",
    "sentiment = pd.read_csv(\"../data/clean_news_sentiment.csv\")\n",
    "market = pd.read_csv(\"../data/market_context_data.csv\")\n",
    "sec = pd.read_csv(\"../data/sec_filings_features.csv\")\n",
    "qbs = pd.read_csv(\"../data/cleaned_quarterly_balance_sheet.csv\")\n",
    "qcf = pd.read_csv(\"../data/cleaned_quarterly_cashflow.csv\")\n",
    "qis = pd.read_csv(\"../data/cleaned_quarterly_income_statement.csv\")\n",
    "\n",
    "# --- Standardize Columns and Dates ---\n",
    "sp500 = standardize_date_column(sp500)\n",
    "nasdaq = standardize_date_column(nasdaq)\n",
    "sp500 = sp500.rename(columns={col: f\"SP500_{col}\" for col in sp500.columns if col != \"date\"})\n",
    "nasdaq = nasdaq.rename(columns={col: f\"Nasdaq_{col}\" for col in nasdaq.columns if col != \"date\"})\n",
    "\n",
    "# --- Aggregating sentiment scores ---\n",
    "sentiment['date'] = pd.to_datetime(sentiment['date'], errors='coerce')\n",
    "sentiment['date'] = sentiment['date'].apply(move_to_monday)\n",
    "sentiment = sentiment.groupby('date', as_index=False)[['neg', 'neu', 'pos', 'compound']].mean()\n",
    "\n",
    "dfs = [\n",
    "    stock, sp500, nasdaq, popular_games_total, registrations,\n",
    "    ccu, session_length, sentiment, market, sec\n",
    "]\n",
    "dfs = [standardize_date_column(df) for df in dfs]\n",
    "\n",
    "# Add quarterly dfs to standardize and convert dates too (but don't merge yet)\n",
    "quarterly_dfs = [qbs, qcf, qis]\n",
    "quarterly_dfs = [standardize_date_column(df) for df in quarterly_dfs]\n",
    "\n",
    "# Ensure all 'date' columns are datetime type\n",
    "for df in dfs + quarterly_dfs:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# --- Merge All Daily DataFrames ---\n",
    "master = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    master = master.merge(df, on='date', how='outer')\n",
    "\n",
    "# --- Forward-fill Quarterly Data to Daily Rows ---\n",
    "for quarterly_df in quarterly_dfs:\n",
    "    quarterly_df = quarterly_df.sort_values('date')\n",
    "    master = pd.merge_asof(master.sort_values('date'), quarterly_df, on='date', direction='backward')\n",
    "\n",
    "# --- Filter to IPO date or later ---\n",
    "ipo_date = pd.to_datetime(\"2021-03-10\")\n",
    "master = master[master[\"date\"] >= ipo_date]\n",
    "\n",
    "# --- Final Touches ---\n",
    "master = master.sort_values('date').reset_index(drop=True)\n",
    "master.to_csv(\"../data/master_dataset.csv\", index=False)\n",
    "print(\"Master dataset saved as master_dataset.csv (with quarterly features forward-filled)\")"
   ],
   "id": "9b3d8d91fda760d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset saved as master_dataset.csv (with quarterly features forward-filled)\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
